{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Dataset load and importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Shape for Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "print(wine.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Description of Wine Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X and y representing samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "X = wine.data[:]\n",
    "print(X)\n",
    "y = wine.target[:]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Data by Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 909)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 13)\n",
      "(45, 13)\n",
      "(133,)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalization accuracy by using cross_val_score of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy value:  0.6837606837606838\n",
      "Test Accuracy value:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#task 3 for Cross-val-score acccuracy\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "cvs1 = cross_val_score(svc, X_train, y_train)\n",
    "accuracy =np.mean(cvs1)\n",
    "print(\"Train accuracy value: \",accuracy)\n",
    "\n",
    "#accuracy for test set\n",
    "cvs2 = cross_val_score(svc, X_test, y_test)\n",
    "accuracy1 = format(np.mean(cvs2))\n",
    "print(\"Test Accuracy value: \",accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_error is 0.3162393162393162\n",
      "Test_error is  0.33333333333333337\n",
      "Error Rate is : 0.28888888888888886\n"
     ]
    }
   ],
   "source": [
    "#test error and train error by svm\n",
    "train_error = 1 - np.mean(cvs1)\n",
    "print(\"Train_error is\",train_error)\n",
    "test_error = 1 - np.mean(cvs2)\n",
    "print(\"Test_error is \",test_error)\n",
    "\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred1 = svc.predict(X_test)\n",
    "err=np.mean(y_pred1 == y_test)\n",
    "print(\"Error Rate is :\",1-err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Observation We can say that Accuracy value is good but can be better for training set according to the results. Moreover, for test set accuracy and error rate we can say that the values are low as expected compared to training set. We can say that according to observation, model trained is underfitting. But we can increase the both results by implementing various algorithms (Feature Enginnering, Bagging, Boosting) to increase the accuracy on both tain and test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Normalization techniques to scale data and Using pipeline for to prevent data leak into test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), SVC())\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min-Max Scaler Data Normalizer using pipeline to avoid Data snooping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.9925925925925926\n",
      "Test set score: 0.9555555555555556\n",
      "Test error Rate score: 0.0444444444444444\n"
     ]
    }
   ],
   "source": [
    "#for min max Scaler value SVM::\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C': [0.01, 0.1, 1, 10, 100],\n",
    "'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "pipe = make_pipeline(MinMaxScaler(), SVC())\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid)\n",
    "grid.fit(X_train,y_train)\n",
    "print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
    "score = grid.score(X_test,y_test)\n",
    "print(\"Test set score:\",score)\n",
    "print(\"Test error Rate score:\",1-score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard-Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.9774928774928775\n",
      "Test set score: 0.9777777777777777\n",
      "Test error Rate score: 0.022222222222222254\n"
     ]
    }
   ],
   "source": [
    "#task2 for Standard Scaler\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SVC())\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid)\n",
    "grid.fit(X_train,y_train)\n",
    "print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
    "score = grid.score(X_test,y_test)\n",
    "print(\"Test set score:\",score)\n",
    "print(\"Test error Rate score:\",1-score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robust-Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.9925925925925926\n",
      "Test set score: 0.9777777777777777\n",
      "Test error Rate score: 0.022222222222222254\n"
     ]
    }
   ],
   "source": [
    "#task for Robust Scaler\n",
    "pipe = make_pipeline(RobustScaler(), SVC())\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid)\n",
    "grid.fit(X_train, y_train);\n",
    "print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
    "score= grid.score(X_test,y_test)\n",
    "print(\"Test set score:\",score)\n",
    "print(\"Test error Rate score:\",1-score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.9321937321937324\n",
      "Test set score: 0.9555555555555556\n",
      "Test error Rate score: 0.0444444444444444\n"
     ]
    }
   ],
   "source": [
    "#task for Normalizer\n",
    "pipe = make_pipeline(Normalizer(), SVC())\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid)\n",
    "grid.fit(X_train, y_train);\n",
    "print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
    "score = grid.score(X_test,y_test)\n",
    "print(\"Test set score:\",score)\n",
    "print(\"Test error Rate score:\",1-score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Observation we observe that Robust-Scaler and Standard-Scaler gives the same Accuracy for both is same. We use RobustScaler in this case and we predict the labels using this method as considering the best fit and normalizer according to the answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels are as Follows: [1 2 0 1 0 0 1 2 1 0 1 0 0 2 1 1 1 0 2 2 2 1 1 1 1 1 0 0 1 2 2 2 2 0 1 0 1\n",
      " 1 1 1 0 1 0 1 1]\n",
      "Error Rate is : 0.022222222222222254\n",
      "Target_names ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "#prediction by robust as most best \n",
    "\n",
    "pipe = make_pipeline(RobustScaler(), SVC())\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid)\n",
    "grid.fit(X_train, y_train);\n",
    "score= grid.score(X_test,y_test)\n",
    "y_pred = grid.predict(X_test)\n",
    "err = np.mean(y_pred == y_test)\n",
    "print(\"Labels are as Follows:\",y_pred)\n",
    "print(\"Error Rate is :\",1-err)\n",
    "print(\"Target_names\",wine['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Training Set:  0.8266666666666668\n",
      "Accuracy of Test Set:  0.76\n",
      "Test Error Rate:  0.24\n",
      "Score through mlp classifier is: 0.72\n"
     ]
    }
   ],
   "source": [
    "#task 8 for MLP Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify= y,random_state=909)\n",
    "mlp = MLPClassifier(solver='lbfgs', activation='tanh', random_state=0, hidden_layer_sizes=[10]).fit(X_train,y_train)\n",
    "train_accuracy = cross_val_score(mlp, X_train, y_train)\n",
    "print(\"Accuracy of Training Set: \",np.mean(train_accuracy))\n",
    "\n",
    "test_accuracy = cross_val_score(mlp, X_test, y_test)\n",
    "print(\"Accuracy of Test Set: \",np.mean(test_accuracy))\n",
    "Err = (1 - np.mean(test_accuracy))\n",
    "print(\"Test Error Rate: \",Err)\n",
    "print(\"Score through mlp classifier is:\",mlp.score(X_test, y_test))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_error is  0.16000000000000014\n",
      "Error Rate is using MLP: 0.31999999999999995\n"
     ]
    }
   ],
   "source": [
    "test_error = 1 - np.mean(test_accuracy)\n",
    "print(\"Test_error is \",test_error)\n",
    "\n",
    "mlp.fit(X_train,y_train)\n",
    "y_pred1 = mlp.predict(X_test)\n",
    "err=np.mean(y_pred1 == y_test)\n",
    "print(\"Error Rate is using MLP:\",1-err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that after  implementing MLPClassifier and cross_val score we get less error rate for cross val score compared to MLP Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USPS Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the data and concatenating them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7291, 257)\n",
      "(2007, 257)\n"
     ]
    }
   ],
   "source": [
    "file1 = np.genfromtxt(\"zip.train\", delimiter=\" \")\n",
    "print(file1.shape)\n",
    "file2 = np.genfromtxt(\"zip.test\", delimiter=\" \")\n",
    "print(file2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = np.concatenate([file1,file2])\n",
    "dataset2.shape\n",
    "X2 = dataset2[:,1:]\n",
    "y2 = dataset2[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the Data into Train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train2,X_test2,y_train2,y_test2 = train_test_split(X2,y2,random_state=909)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using svm and cross_val to predict the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Train accuracy value:  0.9691661652859412\n",
      "For Test accuracy value:  0.9561290322580644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train2,y_train2)\n",
    "cvs1 = cross_val_score(svc, X_train2, y_train2)\n",
    "accuracy = np.mean(cvs1)\n",
    "print(\"For Train accuracy value: \",accuracy)\n",
    "\n",
    "cvs2 = cross_val_score(svc, X_test2, y_test2)\n",
    "accuracy1 = format(np.mean(cvs2))\n",
    "print(\"For Test accuracy value: \",accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_error 0.03083383471405876\n",
      "Test_error 0.04387096774193555\n"
     ]
    }
   ],
   "source": [
    "#test error and train error by svm\n",
    "train_error = 1 - np.mean(cvs1)\n",
    "print(\"Train_error\",train_error)\n",
    "test_error = 1 - np.mean(cvs2)\n",
    "print(\"Test_error\",test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all normalization using all scaler and getting their accuracy and error values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9767741935483871"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), SVC())\n",
    "pipe.fit(X_train2, y_train2)\n",
    "pipe.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.9704565907139149\n",
      "Test set score: 0.9793548387096774\n",
      "Test error Rate score: 0.020645161290322567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C': [0.01, 0.1, 1, 10, 100],\n",
    "'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "pipe = make_pipeline(MinMaxScaler(), SVC())\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid)\n",
    "grid.fit(X_train2,y_train2)\n",
    "print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
    "score = grid.score(X_test2,y_test2)\n",
    "print(\"Test set score:\",score)\n",
    "print(\"Test error Rate score:\",1-score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.9651499771164694\n",
      "Test set score: 0.9750537634408603\n",
      "Test error Rate score: 0.024946236559139745\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SVC())\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid)\n",
    "grid.fit(X_train2,y_train2)\n",
    "print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
    "score = grid.score(X_test2,y_test2)\n",
    "print(\"Test set score:\",score)\n",
    "print(\"Test error Rate score:\",1-score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.8937365977075331\n",
      "Test set score: 0.923010752688172\n",
      "Test error Rate score: 0.07698924731182799\n",
      "Best parameters: {'svc__C': 100, 'svc__gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(RobustScaler(), SVC())\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid)\n",
    "grid.fit(X_train2, y_train2);\n",
    "print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
    "score= grid.score(X_test2,y_test2)\n",
    "print(\"Test set score:\",score)\n",
    "print(\"Test error Rate score:\",1-score)\n",
    "print(\"Best parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.9717469132945599\n",
      "Test set score: 0.9789247311827957\n",
      "Test error Rate score: 0.02107526881720434\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(Normalizer(), SVC())\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid)\n",
    "grid.fit(X_train2, y_train2);\n",
    "print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
    "score = grid.score(X_test2,y_test2)\n",
    "print(\"Test set score:\",score)\n",
    "print(\"Test error Rate score:\",1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels are as Follows: [7. 0. 5. ... 6. 9. 6.]\n",
      "Test Error Rate is : 0.020645161290322567\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(MinMaxScaler(), SVC())\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid)\n",
    "grid.fit(X_train2,y_train2)\n",
    "\n",
    "score = grid.score(X_test2,y_test2)\n",
    "y_pred = grid.predict(X_test2)\n",
    "err = np.mean(y_pred == y_test2)\n",
    "print(\"Labels are as Follows:\",y_pred)\n",
    "print(\"Test Error Rate is :\",1-err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result for minmax scaler were best as the error rate is only 0.02 and and it has very good prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Training Set:  0.9317358057831052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Set:  0.76\n",
      "Test Error Rate:  0.07741935483870976\n",
      "Score through mlp classifier is: 0.9453763440860216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#task 8 \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2,random_state=909)\n",
    "mlp = MLPClassifier(solver='adam', activation='tanh', random_state=909, hidden_layer_sizes=[10]).fit(X_train2,y_train2)\n",
    "train_accuracy1 = cross_val_score(mlp, X_train2, y_train2)\n",
    "print(\"Accuracy of Training Set: \",np.mean(train_accuracy1))\n",
    "\n",
    "test_accuracy1 = cross_val_score(mlp, X_test2, y_test2)\n",
    "print(\"Accuracy of Test Set: \",np.mean(test_accuracy))\n",
    "Err = (1 - np.mean(test_accuracy1))\n",
    "print(\"Test Error Rate: \",Err)\n",
    "print(\"Score through mlp classifier is:\",mlp.score(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_error is  0.07741935483870976\n",
      "Error Rate is using MLP: 0.06494623655913978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "test_error2 = 1 - np.mean(test_accuracy1)\n",
    "print(\"Test_error is \",test_error2)\n",
    "\n",
    "mlp.fit(X_train2,y_train2)\n",
    "y_pred2 = mlp.predict(X_test2)\n",
    "err=np.mean(y_pred2 == y_test2)\n",
    "print(\"Error Rate is using MLP:\",1-err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this las task we get good accuracy value through mlp classifier than the cross value score.We used lbgfs cause both datasets are large we can also use adam but it was giving errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
